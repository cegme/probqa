
\section{Background}

In this section, we give the necessary background from the probabilitic knowledge base backed question answering system.
We first describe the set of data sets that underly this work.
We then give a brief description of Markov Logic Networks followed by our definition of a probabilitic knowledgebase.

\subsection{Data Set}

In this demo, we use Freebase, Reverb, and NELL as the underlying knowledge bases.
These knowledge bases store collection of facts as (subject, predicate, object) triples,
representing facts related to well-known entities (people, places, and things). They differ
in scale, schema and construction methods.

\textbf{Freebase.} Freebase is a web-scale, human-crafted, high precision knowledge base of
well-known topics (entities) and facts~\cite{bollacker2008freebase}.
As of current writing, it contains 47.5 million entities
and 2.9 billion facts, spanning a variety of areas including People, Sports, Music, Internet,
Books, etc, organized into domains. The Freebase KB is publicly accessible as rdf triples.

\textbf{ReVerb.} ReVerb is an automatic knowledge base construction system
that extracts entities and facts from natural language text~\cite{fader2011identifying}.
It is a universal schema extraction system, extracting both entities and predicates (relations).
The extracted tuples are publicly available, and we use
its ClueWeb extractions, which contains 14.7 million facts, annotated by their confidence
and source URLs.

\textbf{NELL.} NELL is a never-ending knowledge extraction system~\cite{mitchell2015never}. It extracts facts and updates
its knowledge base every day. As of current writing, it has extracted 84.6 million facts, of
which 2.2 million are believed to have high confidence. Like ReVerb, each fact is annotated
by its confidence and source URLs. It also contains information on which extraction
algorithms are used to extract each fact.

In both ReVerb and NELL KBs, recent works have tried to mine \emph{first-order inference rules}.
An inference rule states causal relationships among facts, for example, we have
\[
\text{bornIn}(x, y), \text{locatedIn}(y, z) \rightarrow \text{bornIn}(x, z).
\]
This rule states that if a person \(x\) was born in location \(y\), and location \(y\)
is located within another location \(z\), then person \(x\) is also born in location \(z\).
The Sherlock-Holmes system mines 30,912 inference rules from ReVerb, and NELL also
has 2 thousand rules with an inference engine as one of its extraction component.









\subsection{Markov Logic Networks}

Markov Logic Networks (MLNs) are the standard method of modeling uncertainty.
MLNs are mare up of a weighted first-order formulae of the form \(\{F_i, W_i\}\),
where \(F_i\) is a logical expression and \(W_i\) is a weight
specifying how likely it is that the formula is true.

For example, the MLN clauses below state two different sets of information.

%\vspace{-1em}
%\begin{table}[h]
\begin{tabular}{l l}
  \(0.96\) & bornInState (Obama, Hawaii) \\
  \(1.40\) & \( \forall x \in Person, \forall y \in State, \forall z \in Country: \) \\
           & \(bornState(x,y) \wedge isState(y,z) \rightarrow bornCountry(x, z)\)
\end{tabular}
%\end{table}
%\vspace{-1em}

The first clause states that that Obama was born in the state of Hawaii.
The second formulate is an inference rule that states that if a person \(x\) is born in a state \(y\), and a state \(y\) is in a part of a country \(z\),
then that person \(x\) is born in the country \(z\).
These formula do not necessarily apply,
the weights of 0.96 and 1.40 specify the strength of the formula; stronger rules have a lower chance of being violated.
Deterministic rules, or rules that can never be violated are given an infinite weights of $\inf$.


\subsubsection{Grounding}

MLNs are a template generating ground factor graphs.
A factor graph is a set of factors \(\Phi = \{ \phi_1, \ldots, \phi_{|\Phi|} \} \),
where each factor \(\phi_i\) is a function \(\phi_i (\mathbf{X}_i)\) over a
vector of random variables \(\mathbf{X}_i\).
\ceg{Maybe add figure of ground factor graph}

We use the term grounding to refer to the processes of creating the factor graph from an
MLN and a set of clauses.
Each node in the factor graph is a ground atom and has a boolean variable that represents its truth value.
We an perform the grounding step inside the database using a simple series of database queries~\cite{chen2014knowledge}.

For each possible grounding of formula \(F_i\) we create a ground factor
\(\phi_i(\mathbf{X}_i)\) with a value of 1 if the grounding is true, otherwise
\(e^{W_i}\). The marginal probability distribution of a set of grounded atoms \(\mathbf{X}\) is defined as
\begin{equation}
\label{eq:probqa-marginal}
P(\mathbf{X} = x) = \frac{1}{Z} \prod_i \phi_i (\mathbf{X}_i) = \frac{1}{Z} \text{exp} \left( \sum_i W_i n_i(x) \right),
\end{equation}
where \(n_i(x)\) is the number of true groundings of rule \(F_i\) in x, \(W_i\) is its weight, and \(Z\) is the partition function.
This probability gives use the probabilitity of one particular state of a knowledge base.


%\subsubsection{Rule Generation}



%\subsubsection{Inference}


\subsection{Probabilitic Knowledge Bases}

We use a definition of probabilistic knowledge bases derived in previous work~\cite{chen2014knowledge}.
A probabilistic knowledge base is a 5-tuples \(\Gamma = (\mathcal{E}, \mathcal{C}, \mathcal{R}, \Pi, \mathcal{L})\), where
\begin{enumerate}[leftmargin=0cm,itemindent=.5cm,labelwidth=\itemindent,labelsep=0cm,align=left]
\vspace{-1em}
\item \(\mathcal{E} = \{ e_1, \ldots, e_{|\mathcal{E}|} \} \) is the set of entities.
Each entitie \( e \in \mathcal{E} \) refers to a real-world object.

\vspace{-1em}
\item \(\mathcal{C} = \{ c_1, \ldots, c_{|\mathcal{C}|} \} \) is the set of classes (or types).
Each class \( C \in \mathcal{C} \) maybe be a subset of \(\mathcal{E} : C \subseteq \mathcal{E}\), or an unknown class.

\vspace{-1em}
\item \(\mathcal{R} = \{ R_1, \ldots, R_{|\mathcal{R}|} \} \) is the set of relations.
Each \(R \in \mathcal{R} \) defines a binary relation on \(C_i, C_j \in \mathcal{C}: R: \subseteq C_i \times C_j\).
We call \(C_i, C_j\) the domain and range of \(R\) and use \(R(C_i,C_j)\) to denote the relation and its domain and range.


\vspace{-1em}
\item \(\Pi = \{(r_1, w_1), \ldots, (r_{|\Pi|}, w_{\Pi|})\} \) is a set of weighted facts.
For each \( (r,w) \in \Pi\), \(r\) is a tuple  \((R,x,y)\),
where \(R(C_i,C_j) \in \mathcal{R}, x \in C_i \in C, y \in C_j \in C\), and \((x,y) \in R\);
\(w \in \mathbb{R}\) is a weight indicating how likely it is that \(r\) is true. 

\vspace{-1em}
\item \(\mathcal{L} = \{(F_1,W_1),\ldots, (F_{|\mathcal{L}|}, W_{|\mathcal{L}|}) \} \) is a set of weighted rules.
For each \((F, W) \in \mathcal{L} \), \(F\) is a first-order logic clause, and
\(W \in \mathbb{R} \) us a weight indicating how likely the formula \(F\)
holds. 

\end{enumerate}


\subsubsection{Question Answering}

To answer questions, a mapping must be developed between a known
natural language utterance to subset of all possible facts to present an answer.
We assume that the knowledge base contains that complete set of facts necessary
to find the answer to the question.
Additionally, in order to quantify the truthfulness of each fact, it is
important to enumerate the facts that support the final answer.


In this work, we leverage a new system named SEMPRE which uses supervised
learning of question answer pairs to create a Lambda Dependency-Based
Compositional Semantics language (\(\lambda\)-DCS)~\cite{berant2013semantic}.
The translating to a logical form, such as a (\(\lambda\)-DCS), allows the
semantics to be executed producing a denotation, or an answer to the question.
The \(\lambda\)-DCS can be translated to a SPARQL query for execution over 
freebase of a similar knowledge base where it can be evaluated.



